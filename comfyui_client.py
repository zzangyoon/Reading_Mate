"""
ComfyUI API í´ë¼ì´ì–¸íŠ¸
- Flux ëª¨ë¸ ì „ìš© ì´ë¯¸ì§€ ìƒì„±
- Storybook LoRA ì ìš© 
"""
# uv run comfy launch
# uvicorn backend.app.main:app --reload --host 0.0.0.0 --port 8003

import requests
import json
import time
import uuid
from typing import Dict
from PIL import Image
from pathlib import Path


class ComfyUIClient:
    def __init__(self, server_address: str = "100.100.53.32:8288"):
        """
        ComfyUI í´ë¼ì´ì–¸íŠ¸ ì´ˆê¸°í™”
        
        Args:
            server_address: ComfyUI ì„œë²„ ì£¼ì†Œ (IP:PORT)
        """
        self.server_address = server_address
        self.client_id = str(uuid.uuid4())
    
    def generate_image(self, prompt_data: Dict) -> Dict:
        """
        ì´ë¯¸ì§€ ìƒì„±
        
        Args:
            prompt_data: í”„ë¡¬í”„íŠ¸ ë° íŒŒë¼ë¯¸í„° ë”•ì…”ë„ˆë¦¬
            
        Returns:
            ìƒì„± ê²°ê³¼ (image_path, quality_score ë“±)
        """
        print("ğŸ¨ ì´ë¯¸ì§€ ìƒì„± ì‹œì‘")
        
        # Flux ì›Œí¬í”Œë¡œìš° ìƒì„±
        workflow = self._get_flux_workflow()
        
        # í”„ë¡¬í”„íŠ¸ ì£¼ì…
        workflow = self._inject_prompt(workflow, prompt_data)
        
        # ComfyUIì— ìš”ì²­
        try:
            prompt_id = self._queue_prompt(workflow)
            print(f"âœ… Prompt ID: {prompt_id}")
            
            # ì™„ë£Œ ëŒ€ê¸°
            result = self._wait_for_completion(prompt_id)
            
            # ì´ë¯¸ì§€ ë‹¤ìš´ë¡œë“œ
            image_path = self._download_image(result)
            
            # í’ˆì§ˆ í‰ê°€
            quality_score = self._evaluate_image_quality(image_path)
            
            return {
                "image_path": image_path,
                "prompt_id": prompt_id,
                "quality_score": quality_score,
                "generation_time": 30.0
            }
            
        except Exception as e:
            print(f"âŒ ì˜¤ë¥˜ ë°œìƒ: {type(e).__name__} - {str(e)}")
            raise
    
    def _get_flux_workflow(self) -> Dict:
        """
        Flux ëª¨ë¸ìš© ê¸°ë³¸ ì›Œí¬í”Œë¡œìš° ë°˜í™˜
        
        ì›Œí¬í”Œë¡œìš° êµ¬ì„±:
        - UNETLoader: Flux ëª¨ë¸
        - LoraLoader: Storybook LoRA
        - DualCLIPLoader: CLIP ëª¨ë¸
        - KSampler: ìƒ˜í”Œë§ (Euler, 20 steps, CFG 1.0)
        - VAEDecode: ì´ë¯¸ì§€ ë””ì½”ë”©
        """
        return {
            "18": {
                "class_type": "UNETLoader",
                "inputs": {
                    "unet_name": "flux1-krea-dev_fp8_scaled.safetensors",
                    "weight_dtype": "default"
                }
            },
            "2": {
                "class_type": "LoraLoaderModelOnly",
                "inputs": {
                    "lora_name": "pp-storybook_rank2_bf16.safetensors",
                    "strength_model": 0.8,
                    "model": ["18", 0]
                }
            },
            "13": {
                "class_type": "DualCLIPLoader",
                "inputs": {
                    "clip_name1": "clip_l.safetensors",
                    "clip_name2": "t5xxl_fp16.safetensors",
                    "type": "flux"
                }
            },
            "4": {
                "class_type": "CLIPTextEncode",
                "inputs": {
                    "text": "",
                    "clip": ["13", 0]
                }
            },
            "16": {
                "class_type": "ConditioningZeroOut",
                "inputs": {
                    "conditioning": ["4", 0]
                }
            },
            "10": {
                "class_type": "EmptyLatentImage",
                "inputs": {
                    "width": 1024,
                    "height": 1024,
                    "batch_size": 1
                }
            },
            "3": {
                "class_type": "KSampler",
                "inputs": {
                    "seed": 0,
                    "steps": 20,
                    "cfg": 1.0,
                    "sampler_name": "euler",
                    "scheduler": "simple",
                    "denoise": 1.0,
                    "model": ["2", 0],
                    "positive": ["4", 0],
                    "negative": ["16", 0],
                    "latent_image": ["10", 0]
                }
            },
            "14": {
                "class_type": "VAELoader",
                "inputs": {
                    "vae_name": "ae.safetensors"
                }
            },
            "6": {
                "class_type": "VAEDecode",
                "inputs": {
                    "samples": ["3", 0],
                    "vae": ["14", 0]
                }
            },
            "7": {
                "class_type": "SaveImage",
                "inputs": {
                    "filename_prefix": "ComfyUI",
                    "images": ["6", 0]
                }
            }
        }
    
    def _inject_prompt(self, workflow: Dict, prompt_data: Dict) -> Dict:
        """
        ì›Œí¬í”Œë¡œìš°ì— í”„ë¡¬í”„íŠ¸ ë° íŒŒë¼ë¯¸í„° ì£¼ì…
        
        Args:
            workflow: ì›Œí¬í”Œë¡œìš° ë”•ì…”ë„ˆë¦¬
            prompt_data: í”„ë¡¬í”„íŠ¸ ë°ì´í„°
            
        Returns:
            ì—…ë°ì´íŠ¸ëœ ì›Œí¬í”Œë¡œìš°
        """
        positive_prompt = prompt_data.get("positive", "")
        style_params = prompt_data.get("style_params", {})
        
        # íŒŒë¼ë¯¸í„° ì¶”ì¶œ
        steps = style_params.get("steps", 20)
        cfg = style_params.get("cfg_scale", 1.0)
        sampler = style_params.get("sampler", "euler")
        width = style_params.get("width", 1024)
        height = style_params.get("height", 1024)
        lora_strength = style_params.get("lora_strength", 0.8)
        
        print(f"âœ¨ Positive: {positive_prompt[:100]}...")
        print(f"âš™ï¸ Size: {width}x{height}, Steps: {steps}, CFG: {cfg}, LoRA: {lora_strength}")
        
        # ì›Œí¬í”Œë¡œìš° ì—…ë°ì´íŠ¸
        for node_id, node in workflow.items():
            if not isinstance(node, dict):
                continue
                
            class_type = node.get("class_type", "")
            
            # ì´ë¯¸ì§€ í¬ê¸°
            if class_type == "EmptyLatentImage":
                node["inputs"]["width"] = int(width)
                node["inputs"]["height"] = int(height)
            
            # LoRA ê°•ë„
            elif class_type == "LoraLoaderModelOnly":
                node["inputs"]["strength_model"] = float(lora_strength)
            
            # ìƒ˜í”Œë§ íŒŒë¼ë¯¸í„°
            elif class_type == "KSampler":
                node["inputs"]["seed"] = int(time.time() * 1000) % (2**32)
                node["inputs"]["steps"] = int(steps)
                node["inputs"]["cfg"] = float(cfg)
                node["inputs"]["sampler_name"] = sampler
            
            # Positive í”„ë¡¬í”„íŠ¸
            elif class_type == "CLIPTextEncode" and node_id == "4":
                node["inputs"]["text"] = positive_prompt
        
        return workflow
    
    def _queue_prompt(self, workflow: Dict) -> str:
        """ComfyUI íì— í”„ë¡¬í”„íŠ¸ ì œì¶œ"""
        url = f"http://{self.server_address}/prompt"
        payload = {"prompt": workflow, "client_id": self.client_id}
        
        response = requests.post(url, json=payload, timeout=10)
        response.raise_for_status()
        return response.json()["prompt_id"]
    
    def _wait_for_completion(self, prompt_id: str, timeout: int = 300) -> Dict:
        """ì´ë¯¸ì§€ ìƒì„± ì™„ë£Œ ëŒ€ê¸°"""
        print("â³ ì´ë¯¸ì§€ ìƒì„± ëŒ€ê¸° ì¤‘...")
        
        start_time = time.time()
        
        while time.time() - start_time < timeout:
            try:
                response = requests.get(
                    f"http://{self.server_address}/history/{prompt_id}"
                )
                if response.status_code == 200:
                    history = response.json()
                    if prompt_id in history:
                        print("âœ… ìƒì„± ì™„ë£Œ!")
                        return history[prompt_id]
            except:
                pass
            
            time.sleep(2)
        
        raise TimeoutError("ì´ë¯¸ì§€ ìƒì„± ì‹œê°„ ì´ˆê³¼")
    
    def _download_image(self, result: Dict) -> str:
        """ìƒì„±ëœ ì´ë¯¸ì§€ ë‹¤ìš´ë¡œë“œ"""
        outputs = result.get("outputs", {})
        
        for node_id, node_output in outputs.items():
            if "images" in node_output:
                image_info = node_output["images"][0]
                filename = image_info["filename"]
                subfolder = image_info.get("subfolder", "")
                file_type = image_info.get("type", "output")
                
                # ì´ë¯¸ì§€ ë‹¤ìš´ë¡œë“œ
                url = f"http://{self.server_address}/view"
                params = {
                    "filename": filename,
                    "subfolder": subfolder,
                    "type": file_type
                }
                
                response = requests.get(url, params=params)
                response.raise_for_status()
                
                # ì €ì¥
                Path("generated_images").mkdir(exist_ok=True)
                output_path = f"generated_images/{filename}"
                
                with open(output_path, "wb") as f:
                    f.write(response.content)
                
                print(f"ğŸ’¾ ì €ì¥ ì™„ë£Œ: {output_path}")
                return output_path
        
        raise ValueError("ìƒì„±ëœ ì´ë¯¸ì§€ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤")
    
    def _evaluate_image_quality(self, image_path: str) -> float:
        """
        ì´ë¯¸ì§€ í’ˆì§ˆ í‰ê°€ (ê°„ë‹¨í•œ íœ´ë¦¬ìŠ¤í‹±)
        
        - í•´ìƒë„ ê¸°ë°˜ ì ìˆ˜
        - íŒŒì¼ í¬ê¸° ê¸°ë°˜ ì ìˆ˜
        """
        try:
            img = Image.open(image_path)
            width, height = img.size
            
            # í•´ìƒë„ ì ìˆ˜
            resolution_score = min(1.0, (width * height) / (1024 * 1024))
            
            # íŒŒì¼ í¬ê¸° ì ìˆ˜
            import os
            file_size = os.path.getsize(image_path)
            size_score = min(1.0, file_size / (100 * 1024))
            
            return (resolution_score + size_score) / 2
            
        except Exception as e:
            print(f"âš ï¸ í’ˆì§ˆ í‰ê°€ ì˜¤ë¥˜: {e}")
            return 0.5
        
        # uv run comfy launch