"""
ì „ìì±… ë²¡í„° ê²€ìƒ‰ ì—”ì§„
- Chroma ë²¡í„° DB ê¸°ë°˜ ìœ ì‚¬ ë¬¸ì¥ ê²€ìƒ‰
- ìë™ í‚¤ì›Œë“œ ì¶”ì¶œ (ê¸´ ë¬¸ì¥ ì…ë ¥ ì‹œ)
"""
from typing import List, Dict
from langchain_openai import OpenAIEmbeddings
from langchain_chroma import Chroma
from dotenv import load_dotenv
from openai import OpenAI
import os

load_dotenv()


class VectorSearchEngine:
    def __init__(
        self, 
        db_path: str = "./99_vectorstore/e_book_db",
        collection_name: str = "the_wizard_of_oz",
        embedding_model: str = "text-embedding-3-small"
    ):
        """
        ë²¡í„° ê²€ìƒ‰ ì—”ì§„ ì´ˆê¸°í™”
        
        Args:
            db_path: Chroma DB ì €ì¥ ê²½ë¡œ
            collection_name: ì»¬ë ‰ì…˜ ì´ë¦„
            embedding_model: OpenAI ì„ë² ë”© ëª¨ë¸
        """
        self.embedding = OpenAIEmbeddings(model=embedding_model)
        self.vectorstore = Chroma(
            persist_directory=db_path,
            embedding_function=self.embedding,
            collection_name=collection_name
        )
        self.openai_client = OpenAI(api_key=os.getenv("OPENAI_API_KEY"))
    
    def extract_keywords(self, text: str) -> str:
        """
        ê¸´ ë¬¸ì¥ì—ì„œ í•µì‹¬ í‚¤ì›Œë“œ ìë™ ì¶”ì¶œ
        
        Args:
            text: ì›ë³¸ ë¬¸ì¥
            
        Returns:
            ì¶”ì¶œëœ í•µì‹¬ í‚¤ì›Œë“œ
        """
        try:
            response = self.openai_client.chat.completions.create(
                model="gpt-4o-mini",
                messages=[{
                    "role": "user",
                    "content": f"""ë‹¤ìŒ ë¬¸ì¥ì—ì„œ ê²€ìƒ‰ì— ìœ ìš©í•œ í•µì‹¬ í‚¤ì›Œë“œë§Œ ì¶”ì¶œí•˜ì„¸ìš”.

ë¬¸ì¥: {text}

ê·œì¹™:
- ëª…ì‚¬, ë™ì‚¬, ê³ ìœ ëª…ì‚¬ ì¤‘ì‹¬
- 5-10ê°œ í‚¤ì›Œë“œ
- ë¶ˆí•„ìš”í•œ ì¡°ì‚¬, ë¶€ì‚¬ ì œì™¸
- ê³µë°±ìœ¼ë¡œ êµ¬ë¶„

í‚¤ì›Œë“œë§Œ ì¶œë ¥:"""
                }],
                temperature=0.3
            )
            
            keywords = response.choices[0].message.content.strip()
            print(f"ğŸ” ì¶”ì¶œëœ í‚¤ì›Œë“œ: {keywords}")
            return keywords
            
        except Exception as e:
            print(f"âš ï¸ í‚¤ì›Œë“œ ì¶”ì¶œ ì‹¤íŒ¨: {e}, ì›ë¬¸ ì‚¬ìš©")
            return text
    
    def search_relevant_content(
        self, 
        query: str, 
        top_k: int = 5,
        auto_extract_keywords: bool = True
    ) -> List[Dict]:
        """
        ìœ ì‚¬ ë¬¸ì¥ ê²€ìƒ‰
        
        Args:
            query: ê²€ìƒ‰í•  í‚¤ì›Œë“œ/ë¬¸ì¥
            top_k: ë°˜í™˜í•  ë¬¸ì¥ ê°œìˆ˜
            auto_extract_keywords: ê¸´ ë¬¸ì¥ ì‹œ ìë™ í‚¤ì›Œë“œ ì¶”ì¶œ
            
        Returns:
            ê´€ë ¨ ë¬¸ì¥ ë¦¬ìŠ¤íŠ¸ (score í¬í•¨)
        """
        # ê¸´ ë¬¸ì¥ì¸ ê²½ìš° í‚¤ì›Œë“œ ì¶”ì¶œ
        search_query = query
        if auto_extract_keywords and len(query) > 50:
            search_query = self.extract_keywords(query)
        
        # ìœ ì‚¬ë„ ê²€ìƒ‰
        results = self.vectorstore.similarity_search_with_score(
            query=search_query,
            k=top_k
        )
        
        # ê²°ê³¼ í¬ë§·íŒ… (ê±°ë¦¬ â†’ ìœ ì‚¬ë„ ë³€í™˜)
        formatted_results = []
        for doc, distance in results:
            similarity_score = 1 / (1 + distance)
            
            formatted_results.append({
                "text": doc.page_content,
                "score": similarity_score,
                "metadata": doc.metadata
            })
        
        return formatted_results
    
    def count_documents(self) -> int:
        """ì €ì¥ëœ ë¬¸ì„œ ê°œìˆ˜ ë°˜í™˜"""
        return self.vectorstore._collection.count()